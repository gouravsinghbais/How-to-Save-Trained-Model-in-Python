{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6cfc75a",
   "metadata": {},
   "source": [
    "## Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "247d6825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 00:51:33.273624: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# load dependencies\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acefe356",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09a5f1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width        Class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "url = \"iris.data\"\n",
    "\n",
    "# column names to use\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
    "\n",
    "# read the dataset from URL\n",
    "dataset = pd.read_csv(url, names=names) \n",
    "\n",
    "# check first few rows of data\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0217de62",
   "metadata": {},
   "source": [
    "# Label Encode Output Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f917e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# seperate the independent and dependent features\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values \n",
    "\n",
    "# encode output variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7794c25e",
   "metadata": {},
   "source": [
    "## Split Data and Standradize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9acbf3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into random training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) \n",
    "\n",
    "# feature standardization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db59f1",
   "metadata": {},
   "source": [
    "## Convert Data with NumPy Arrays to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9951ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data numpy arrays to tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8351dc",
   "metadata": {},
   "source": [
    "## Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee57beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "class NeuralNetworkClassificationModel(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(NeuralNetworkClassificationModel,self).__init__()\n",
    "        self.input_layer    = nn.Linear(input_dim,128)\n",
    "        self.hidden_layer1  = nn.Linear(128,64)\n",
    "        self.output_layer   = nn.Linear(64,output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    \n",
    "    def forward(self,x):\n",
    "        out =  self.relu(self.input_layer(x))\n",
    "        out =  self.relu(self.hidden_layer1(out))\n",
    "        out =  self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709de31d",
   "metadata": {},
   "source": [
    "## Define Model Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f5f3deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input and output dimensions\n",
    "input_dim  = 4 \n",
    "output_dim = 3\n",
    "model = NeuralNetworkClassificationModel(input_dim,output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7c9350",
   "metadata": {},
   "source": [
    "## Define Model Configuration and Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e5d466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our optimizer and loss function object\n",
    "learning_rate = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "# define training steps\n",
    "def train_network(model,optimizer,criterion,X_train,y_train,X_test,y_test,num_epochs,train_losses,test_losses):\n",
    "    for epoch in range(num_epochs):\n",
    "        # clear out the gradients from the last step loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward feed\n",
    "        output_train = model(X_train)\n",
    "\n",
    "        # calculate the loss\n",
    "        loss_train = criterion(output_train, y_train)\n",
    "        \n",
    "\n",
    "        # backward propagation: calculate gradients\n",
    "        loss_train.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        output_test = model(X_test)\n",
    "        loss_test = criterion(output_test,y_test)\n",
    "\n",
    "        train_losses[epoch] = loss_train.item()\n",
    "        test_losses[epoch] = loss_test.item()\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {loss_train.item():.4f}, Test Loss: {loss_test.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01384754",
   "metadata": {},
   "source": [
    "## Train Pytorch Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8ba3907",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "train_losses = np.zeros(num_epochs)\n",
    "test_losses  = np.zeros(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c724e1c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000, Train Loss: 0.0228, Test Loss: 0.1840\n",
      "Epoch 100/1000, Train Loss: 0.0018, Test Loss: 0.2661\n",
      "Epoch 150/1000, Train Loss: 0.0001, Test Loss: 0.2478\n",
      "Epoch 200/1000, Train Loss: 0.0000, Test Loss: 0.2535\n",
      "Epoch 250/1000, Train Loss: 0.0000, Test Loss: 0.2607\n",
      "Epoch 300/1000, Train Loss: 0.0000, Test Loss: 0.2629\n",
      "Epoch 350/1000, Train Loss: 0.0000, Test Loss: 0.2645\n",
      "Epoch 400/1000, Train Loss: 0.0000, Test Loss: 0.2661\n",
      "Epoch 450/1000, Train Loss: 0.0000, Test Loss: 0.2669\n",
      "Epoch 500/1000, Train Loss: 0.0000, Test Loss: 0.2689\n",
      "Epoch 550/1000, Train Loss: 0.0000, Test Loss: 0.2703\n",
      "Epoch 600/1000, Train Loss: 0.0000, Test Loss: 0.2702\n",
      "Epoch 650/1000, Train Loss: 0.0000, Test Loss: 0.2709\n",
      "Epoch 700/1000, Train Loss: 0.0000, Test Loss: 0.2731\n",
      "Epoch 750/1000, Train Loss: 0.0000, Test Loss: 0.2729\n",
      "Epoch 800/1000, Train Loss: 0.0000, Test Loss: 0.2718\n",
      "Epoch 850/1000, Train Loss: 0.0000, Test Loss: 0.2731\n",
      "Epoch 900/1000, Train Loss: 0.0000, Test Loss: 0.2740\n",
      "Epoch 950/1000, Train Loss: 0.0000, Test Loss: 0.2733\n",
      "Epoch 1000/1000, Train Loss: 0.0000, Test Loss: 0.2734\n"
     ]
    }
   ],
   "source": [
    "train_network(model,optimizer,criterion,X_train,y_train,X_test,y_test,num_epochs,train_losses,test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78287132",
   "metadata": {},
   "source": [
    "## Save Model Weights and Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6af9cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model \n",
    "torch.save(model, 'model_pytorch.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9858ff9a",
   "metadata": {},
   "source": [
    "## Load Model Weights and Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1f26fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetworkClassificationModel(\n",
       "  (input_layer): Linear(in_features=4, out_features=128, bias=True)\n",
       "  (hidden_layer1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model = torch.load('model_pytorch.pt')\n",
    "# check model summary\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec8850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
